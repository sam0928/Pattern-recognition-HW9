{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# B0829024 HW"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## Modern convnet architecture patterns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Modularity, hierarchy, and reuse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Residual connections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Residual block where the number of filters changes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "inputs = keras.Input(shape=(32, 32, 3))\n",
    "x = layers.Conv2D(32, 3, activation=\"relu\")(inputs)\n",
    "residual = x\n",
    "x = layers.Conv2D(64, 3, activation=\"relu\", padding=\"same\")(x)\n",
    "residual = layers.Conv2D(64, 1)(residual)\n",
    "x = layers.add([x, residual])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Case where target block includes a max pooling layer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "inputs = keras.Input(shape=(32, 32, 3))\n",
    "x = layers.Conv2D(32, 3, activation=\"relu\")(inputs)\n",
    "residual = x\n",
    "x = layers.Conv2D(64, 3, activation=\"relu\", padding=\"same\")(x)\n",
    "x = layers.MaxPooling2D(2, padding=\"same\")(x)\n",
    "residual = layers.Conv2D(64, 1, strides=2)(residual)\n",
    "x = layers.add([x, residual])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_9\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_30 (InputLayer)          [(None, 32, 32, 3)]  0           []                               \n",
      "                                                                                                  \n",
      " rescaling_9 (Rescaling)        (None, 32, 32, 3)    0           ['input_30[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_141 (Conv2D)            (None, 32, 32, 32)   896         ['rescaling_9[0][0]']            \n",
      "                                                                                                  \n",
      " conv2d_142 (Conv2D)            (None, 32, 32, 32)   9248        ['conv2d_141[0][0]']             \n",
      "                                                                                                  \n",
      " max_pooling2d_28 (MaxPooling2D  (None, 16, 16, 32)  0           ['conv2d_142[0][0]']             \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv2d_143 (Conv2D)            (None, 16, 16, 32)   128         ['rescaling_9[0][0]']            \n",
      "                                                                                                  \n",
      " add_47 (Add)                   (None, 16, 16, 32)   0           ['max_pooling2d_28[0][0]',       \n",
      "                                                                  'conv2d_143[0][0]']             \n",
      "                                                                                                  \n",
      " conv2d_144 (Conv2D)            (None, 16, 16, 64)   18496       ['add_47[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_145 (Conv2D)            (None, 16, 16, 64)   36928       ['conv2d_144[0][0]']             \n",
      "                                                                                                  \n",
      " max_pooling2d_29 (MaxPooling2D  (None, 8, 8, 64)    0           ['conv2d_145[0][0]']             \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv2d_146 (Conv2D)            (None, 8, 8, 64)     2112        ['add_47[0][0]']                 \n",
      "                                                                                                  \n",
      " add_48 (Add)                   (None, 8, 8, 64)     0           ['max_pooling2d_29[0][0]',       \n",
      "                                                                  'conv2d_146[0][0]']             \n",
      "                                                                                                  \n",
      " conv2d_147 (Conv2D)            (None, 8, 8, 128)    73856       ['add_48[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_148 (Conv2D)            (None, 8, 8, 128)    147584      ['conv2d_147[0][0]']             \n",
      "                                                                                                  \n",
      " conv2d_149 (Conv2D)            (None, 8, 8, 128)    8320        ['add_48[0][0]']                 \n",
      "                                                                                                  \n",
      " add_49 (Add)                   (None, 8, 8, 128)    0           ['conv2d_148[0][0]',             \n",
      "                                                                  'conv2d_149[0][0]']             \n",
      "                                                                                                  \n",
      " global_average_pooling2d_9 (Gl  (None, 128)         0           ['add_49[0][0]']                 \n",
      " obalAveragePooling2D)                                                                            \n",
      "                                                                                                  \n",
      " dense_9 (Dense)                (None, 1)            129         ['global_average_pooling2d_9[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 297,697\n",
      "Trainable params: 297,697\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "inputs = keras.Input(shape=(32, 32, 3))\n",
    "x = layers.Rescaling(1./255)(inputs)\n",
    "\n",
    "def residual_block(x, filters, pooling=False):\n",
    "    residual = x\n",
    "    x = layers.Conv2D(filters, 3, activation=\"relu\", padding=\"same\")(x)\n",
    "    x = layers.Conv2D(filters, 3, activation=\"relu\", padding=\"same\")(x)\n",
    "    if pooling:\n",
    "        x = layers.MaxPooling2D(2, padding=\"same\")(x)\n",
    "        residual = layers.Conv2D(filters, 1, strides=2)(residual)\n",
    "    elif filters != residual.shape[-1]:\n",
    "        residual = layers.Conv2D(filters, 1)(residual)\n",
    "    x = layers.add([x, residual])\n",
    "    return x\n",
    "\n",
    "x = residual_block(x, filters=32, pooling=True)\n",
    "x = residual_block(x, filters=64, pooling=True)\n",
    "x = residual_block(x, filters=128, pooling=False)\n",
    "\n",
    "x = layers.GlobalAveragePooling2D()(x)\n",
    "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Batch normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Depthwise separable convolutions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Putting it together: A mini Xception-like model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "# from google.colab import files\n",
    "# files.upload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "# !mkdir ~/.kaggle\n",
    "# !cp kaggle.json ~/.kaggle/\n",
    "# !chmod 600 ~/.kaggle/kaggle.json\n",
    "# !kaggle competitions download -c dogs-vs-cats\n",
    "# !unzip -qq train.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2000 files belonging to 2 classes.\n",
      "Found 1000 files belonging to 2 classes.\n",
      "Found 2000 files belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "import os, shutil, pathlib\n",
    "from tensorflow.keras.utils import image_dataset_from_directory\n",
    "\n",
    "# original_dir = pathlib.Path(\"train\")\n",
    "# new_base_dir = pathlib.Path(\"cats_vs_dogs_small\")\n",
    "\n",
    "original_dir = pathlib.Path('E:\\Code\\Github\\PatternRecognition_HW\\HW08\\train')\n",
    "new_base_dir = pathlib.Path('E:\\Code\\Github\\PatternRecognition_HW\\HW08\\cats_vs_dogs_small')\n",
    "\n",
    "def make_subset(subset_name, start_index, end_index):\n",
    "    for category in (\"cat\", \"dog\"):\n",
    "        dir = new_base_dir / subset_name / category\n",
    "        os.makedirs(dir)\n",
    "        fnames = [f\"{category}.{i}.jpg\" for i in range(start_index, end_index)]\n",
    "        for fname in fnames:\n",
    "            shutil.copyfile(src=original_dir / fname,\n",
    "                            dst=dir / fname)\n",
    "\n",
    "# make_subset(\"train\", start_index=0, end_index=1000)\n",
    "# make_subset(\"validation\", start_index=1000, end_index=1500)\n",
    "# make_subset(\"test\", start_index=1500, end_index=2500)\n",
    "\n",
    "train_dataset = image_dataset_from_directory(\n",
    "    new_base_dir / \"train\",\n",
    "    image_size=(180, 180),\n",
    "    batch_size=32)\n",
    "validation_dataset = image_dataset_from_directory(\n",
    "    new_base_dir / \"validation\",\n",
    "    image_size=(180, 180),\n",
    "    batch_size=32)\n",
    "test_dataset = image_dataset_from_directory(\n",
    "    new_base_dir / \"test\",\n",
    "    image_size=(180, 180),\n",
    "    batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "data_augmentation = keras.Sequential(\n",
    "    [\n",
    "        layers.RandomFlip(\"horizontal\"),\n",
    "        layers.RandomRotation(0.1),\n",
    "        layers.RandomZoom(0.2),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "inputs = keras.Input(shape=(180, 180, 3))\n",
    "x = data_augmentation(inputs)\n",
    "\n",
    "x = layers.Rescaling(1./255)(x)\n",
    "x = layers.Conv2D(filters=32, kernel_size=5, use_bias=False)(x)\n",
    "\n",
    "for size in [32, 64, 128, 256, 512]:\n",
    "    residual = x\n",
    "\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation(\"relu\")(x)\n",
    "    x = layers.SeparableConv2D(size, 3, padding=\"same\", use_bias=False)(x)\n",
    "\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation(\"relu\")(x)\n",
    "    x = layers.SeparableConv2D(size, 3, padding=\"same\", use_bias=False)(x)\n",
    "\n",
    "    x = layers.MaxPooling2D(3, strides=2, padding=\"same\")(x)\n",
    "\n",
    "    residual = layers.Conv2D(\n",
    "        size, 1, strides=2, padding=\"same\", use_bias=False)(residual)\n",
    "    x = layers.add([x, residual])\n",
    "\n",
    "x = layers.GlobalAveragePooling2D()(x)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "63/63 [==============================] - 41s 537ms/step - loss: 0.7135 - accuracy: 0.5725 - val_loss: 0.7073 - val_accuracy: 0.5000\n",
      "Epoch 2/100\n",
      "63/63 [==============================] - 27s 422ms/step - loss: 0.6593 - accuracy: 0.5925 - val_loss: 0.6987 - val_accuracy: 0.5000\n",
      "Epoch 3/100\n",
      "63/63 [==============================] - 32s 499ms/step - loss: 0.6521 - accuracy: 0.6200 - val_loss: 0.7032 - val_accuracy: 0.5000\n",
      "Epoch 4/100\n",
      "63/63 [==============================] - 32s 507ms/step - loss: 0.6189 - accuracy: 0.6655 - val_loss: 0.6993 - val_accuracy: 0.5000\n",
      "Epoch 5/100\n",
      "63/63 [==============================] - 31s 496ms/step - loss: 0.5919 - accuracy: 0.6930 - val_loss: 0.7272 - val_accuracy: 0.5000\n",
      "Epoch 6/100\n",
      "63/63 [==============================] - 32s 500ms/step - loss: 0.5745 - accuracy: 0.7025 - val_loss: 0.7131 - val_accuracy: 0.4990\n",
      "Epoch 7/100\n",
      "63/63 [==============================] - 32s 506ms/step - loss: 0.5500 - accuracy: 0.7305 - val_loss: 0.9001 - val_accuracy: 0.5000\n",
      "Epoch 8/100\n",
      "63/63 [==============================] - 31s 492ms/step - loss: 0.5496 - accuracy: 0.7400 - val_loss: 0.7476 - val_accuracy: 0.5140\n",
      "Epoch 9/100\n",
      "63/63 [==============================] - 22s 353ms/step - loss: 0.5228 - accuracy: 0.7425 - val_loss: 0.7280 - val_accuracy: 0.5660\n",
      "Epoch 10/100\n",
      "63/63 [==============================] - 31s 494ms/step - loss: 0.5138 - accuracy: 0.7505 - val_loss: 0.8662 - val_accuracy: 0.5830\n",
      "Epoch 11/100\n",
      "63/63 [==============================] - 31s 493ms/step - loss: 0.4970 - accuracy: 0.7635 - val_loss: 0.6105 - val_accuracy: 0.6790\n",
      "Epoch 12/100\n",
      "63/63 [==============================] - 32s 510ms/step - loss: 0.4962 - accuracy: 0.7545 - val_loss: 0.6766 - val_accuracy: 0.6260\n",
      "Epoch 13/100\n",
      "63/63 [==============================] - 32s 508ms/step - loss: 0.4838 - accuracy: 0.7680 - val_loss: 0.5809 - val_accuracy: 0.6990\n",
      "Epoch 14/100\n",
      "63/63 [==============================] - 32s 508ms/step - loss: 0.4709 - accuracy: 0.7810 - val_loss: 1.3401 - val_accuracy: 0.5340\n",
      "Epoch 15/100\n",
      "63/63 [==============================] - 31s 491ms/step - loss: 0.4568 - accuracy: 0.7855 - val_loss: 0.7847 - val_accuracy: 0.6750\n",
      "Epoch 16/100\n",
      "63/63 [==============================] - 32s 512ms/step - loss: 0.4315 - accuracy: 0.8130 - val_loss: 0.5319 - val_accuracy: 0.7680\n",
      "Epoch 17/100\n",
      "63/63 [==============================] - 27s 433ms/step - loss: 0.4277 - accuracy: 0.8120 - val_loss: 0.9704 - val_accuracy: 0.6530\n",
      "Epoch 18/100\n",
      "63/63 [==============================] - 31s 500ms/step - loss: 0.4118 - accuracy: 0.8200 - val_loss: 1.1865 - val_accuracy: 0.5350\n",
      "Epoch 19/100\n",
      "63/63 [==============================] - 32s 501ms/step - loss: 0.4054 - accuracy: 0.8105 - val_loss: 0.5281 - val_accuracy: 0.7780\n",
      "Epoch 20/100\n",
      "63/63 [==============================] - 32s 505ms/step - loss: 0.4111 - accuracy: 0.8090 - val_loss: 0.8618 - val_accuracy: 0.6230\n",
      "Epoch 21/100\n",
      "63/63 [==============================] - 32s 500ms/step - loss: 0.3938 - accuracy: 0.8260 - val_loss: 0.9996 - val_accuracy: 0.5900\n",
      "Epoch 22/100\n",
      "63/63 [==============================] - 32s 499ms/step - loss: 0.3814 - accuracy: 0.8335 - val_loss: 0.6669 - val_accuracy: 0.6810\n",
      "Epoch 23/100\n",
      "63/63 [==============================] - 32s 509ms/step - loss: 0.3887 - accuracy: 0.8315 - val_loss: 0.5620 - val_accuracy: 0.7330\n",
      "Epoch 24/100\n",
      "63/63 [==============================] - 32s 503ms/step - loss: 0.3706 - accuracy: 0.8450 - val_loss: 0.4635 - val_accuracy: 0.7900\n",
      "Epoch 25/100\n",
      "63/63 [==============================] - 32s 507ms/step - loss: 0.3626 - accuracy: 0.8390 - val_loss: 0.5070 - val_accuracy: 0.7720\n",
      "Epoch 26/100\n",
      "63/63 [==============================] - 32s 508ms/step - loss: 0.3682 - accuracy: 0.8365 - val_loss: 0.5605 - val_accuracy: 0.7470\n",
      "Epoch 27/100\n",
      "63/63 [==============================] - 31s 495ms/step - loss: 0.3540 - accuracy: 0.8445 - val_loss: 1.8395 - val_accuracy: 0.5800\n",
      "Epoch 28/100\n",
      "63/63 [==============================] - 32s 500ms/step - loss: 0.3509 - accuracy: 0.8460 - val_loss: 0.4632 - val_accuracy: 0.7960\n",
      "Epoch 29/100\n",
      "63/63 [==============================] - 31s 495ms/step - loss: 0.3335 - accuracy: 0.8620 - val_loss: 0.5023 - val_accuracy: 0.7800\n",
      "Epoch 30/100\n",
      "63/63 [==============================] - 32s 506ms/step - loss: 0.3247 - accuracy: 0.8570 - val_loss: 0.4386 - val_accuracy: 0.8040\n",
      "Epoch 31/100\n",
      "63/63 [==============================] - 31s 496ms/step - loss: 0.3302 - accuracy: 0.8485 - val_loss: 0.4410 - val_accuracy: 0.7970\n",
      "Epoch 32/100\n",
      "63/63 [==============================] - 31s 498ms/step - loss: 0.3034 - accuracy: 0.8680 - val_loss: 0.6504 - val_accuracy: 0.7600\n",
      "Epoch 33/100\n",
      "63/63 [==============================] - 31s 491ms/step - loss: 0.3127 - accuracy: 0.8665 - val_loss: 0.5403 - val_accuracy: 0.7880\n",
      "Epoch 34/100\n",
      "63/63 [==============================] - 31s 498ms/step - loss: 0.3063 - accuracy: 0.8655 - val_loss: 0.4322 - val_accuracy: 0.8370\n",
      "Epoch 35/100\n",
      "63/63 [==============================] - 32s 503ms/step - loss: 0.3030 - accuracy: 0.8740 - val_loss: 0.4207 - val_accuracy: 0.8030\n",
      "Epoch 36/100\n",
      "63/63 [==============================] - 32s 505ms/step - loss: 0.3014 - accuracy: 0.8660 - val_loss: 0.6295 - val_accuracy: 0.7380\n",
      "Epoch 37/100\n",
      "63/63 [==============================] - 32s 504ms/step - loss: 0.2926 - accuracy: 0.8740 - val_loss: 0.3865 - val_accuracy: 0.8410\n",
      "Epoch 38/100\n",
      "63/63 [==============================] - 31s 495ms/step - loss: 0.2665 - accuracy: 0.8910 - val_loss: 0.5948 - val_accuracy: 0.7940\n",
      "Epoch 39/100\n",
      "63/63 [==============================] - 28s 434ms/step - loss: 0.2872 - accuracy: 0.8840 - val_loss: 0.5283 - val_accuracy: 0.7760\n",
      "Epoch 40/100\n",
      "63/63 [==============================] - 32s 506ms/step - loss: 0.2753 - accuracy: 0.8835 - val_loss: 0.3631 - val_accuracy: 0.8580\n",
      "Epoch 41/100\n",
      "63/63 [==============================] - 32s 501ms/step - loss: 0.2753 - accuracy: 0.8895 - val_loss: 0.6495 - val_accuracy: 0.7250\n",
      "Epoch 42/100\n",
      "63/63 [==============================] - 32s 507ms/step - loss: 0.2569 - accuracy: 0.8930 - val_loss: 0.5856 - val_accuracy: 0.7930\n",
      "Epoch 43/100\n",
      "63/63 [==============================] - 32s 503ms/step - loss: 0.2579 - accuracy: 0.8945 - val_loss: 0.5390 - val_accuracy: 0.8120\n",
      "Epoch 44/100\n",
      "63/63 [==============================] - 31s 495ms/step - loss: 0.2531 - accuracy: 0.8870 - val_loss: 2.0241 - val_accuracy: 0.5690\n",
      "Epoch 45/100\n",
      "63/63 [==============================] - 32s 505ms/step - loss: 0.2366 - accuracy: 0.9065 - val_loss: 0.5129 - val_accuracy: 0.8080\n",
      "Epoch 46/100\n",
      "63/63 [==============================] - 32s 503ms/step - loss: 0.2431 - accuracy: 0.8970 - val_loss: 0.6172 - val_accuracy: 0.7570\n",
      "Epoch 47/100\n",
      "63/63 [==============================] - 31s 497ms/step - loss: 0.2467 - accuracy: 0.9000 - val_loss: 0.6998 - val_accuracy: 0.7630\n",
      "Epoch 48/100\n",
      "63/63 [==============================] - 30s 482ms/step - loss: 0.2476 - accuracy: 0.8980 - val_loss: 1.0030 - val_accuracy: 0.7130\n",
      "Epoch 49/100\n",
      "63/63 [==============================] - 31s 496ms/step - loss: 0.2207 - accuracy: 0.9055 - val_loss: 0.4378 - val_accuracy: 0.8350\n",
      "Epoch 50/100\n",
      "63/63 [==============================] - 31s 496ms/step - loss: 0.2121 - accuracy: 0.9125 - val_loss: 0.5769 - val_accuracy: 0.7740\n",
      "Epoch 51/100\n",
      "63/63 [==============================] - 32s 506ms/step - loss: 0.2444 - accuracy: 0.9005 - val_loss: 0.3978 - val_accuracy: 0.8430\n",
      "Epoch 52/100\n",
      "63/63 [==============================] - 31s 499ms/step - loss: 0.2028 - accuracy: 0.9155 - val_loss: 0.3784 - val_accuracy: 0.8560\n",
      "Epoch 53/100\n",
      "63/63 [==============================] - 31s 497ms/step - loss: 0.2154 - accuracy: 0.9025 - val_loss: 0.6082 - val_accuracy: 0.8210\n",
      "Epoch 54/100\n",
      "63/63 [==============================] - 31s 495ms/step - loss: 0.2138 - accuracy: 0.9115 - val_loss: 0.5440 - val_accuracy: 0.8130\n",
      "Epoch 55/100\n",
      "63/63 [==============================] - 32s 502ms/step - loss: 0.1916 - accuracy: 0.9150 - val_loss: 0.6288 - val_accuracy: 0.7980\n",
      "Epoch 56/100\n",
      "63/63 [==============================] - 32s 499ms/step - loss: 0.2090 - accuracy: 0.9155 - val_loss: 0.5030 - val_accuracy: 0.8340\n",
      "Epoch 57/100\n",
      "63/63 [==============================] - 31s 490ms/step - loss: 0.1922 - accuracy: 0.9170 - val_loss: 0.4073 - val_accuracy: 0.8510\n",
      "Epoch 58/100\n",
      "63/63 [==============================] - 32s 505ms/step - loss: 0.1813 - accuracy: 0.9240 - val_loss: 0.7630 - val_accuracy: 0.7010\n",
      "Epoch 59/100\n",
      "63/63 [==============================] - 32s 503ms/step - loss: 0.1976 - accuracy: 0.9160 - val_loss: 0.3536 - val_accuracy: 0.8720\n",
      "Epoch 60/100\n",
      "63/63 [==============================] - 32s 501ms/step - loss: 0.1821 - accuracy: 0.9245 - val_loss: 0.4454 - val_accuracy: 0.8610\n",
      "Epoch 61/100\n",
      "63/63 [==============================] - 32s 501ms/step - loss: 0.1818 - accuracy: 0.9265 - val_loss: 0.3777 - val_accuracy: 0.8670\n",
      "Epoch 62/100\n",
      "63/63 [==============================] - 32s 511ms/step - loss: 0.1879 - accuracy: 0.9220 - val_loss: 1.4254 - val_accuracy: 0.6570\n",
      "Epoch 63/100\n",
      "63/63 [==============================] - 32s 513ms/step - loss: 0.1918 - accuracy: 0.9280 - val_loss: 0.4841 - val_accuracy: 0.8360\n",
      "Epoch 64/100\n",
      "63/63 [==============================] - 33s 528ms/step - loss: 0.1704 - accuracy: 0.9335 - val_loss: 0.6832 - val_accuracy: 0.8100\n",
      "Epoch 65/100\n",
      "63/63 [==============================] - 34s 535ms/step - loss: 0.1691 - accuracy: 0.9295 - val_loss: 0.7121 - val_accuracy: 0.8210\n",
      "Epoch 66/100\n",
      "63/63 [==============================] - 33s 527ms/step - loss: 0.1680 - accuracy: 0.9330 - val_loss: 0.4298 - val_accuracy: 0.8330\n",
      "Epoch 67/100\n",
      "63/63 [==============================] - 33s 527ms/step - loss: 0.1514 - accuracy: 0.9410 - val_loss: 0.3925 - val_accuracy: 0.8730\n",
      "Epoch 68/100\n",
      "63/63 [==============================] - 34s 536ms/step - loss: 0.1784 - accuracy: 0.9315 - val_loss: 0.3346 - val_accuracy: 0.8680\n",
      "Epoch 69/100\n",
      "63/63 [==============================] - 34s 546ms/step - loss: 0.1643 - accuracy: 0.9360 - val_loss: 0.6059 - val_accuracy: 0.8160\n",
      "Epoch 70/100\n",
      "63/63 [==============================] - 36s 568ms/step - loss: 0.1672 - accuracy: 0.9340 - val_loss: 0.4374 - val_accuracy: 0.8550\n",
      "Epoch 71/100\n",
      "63/63 [==============================] - 33s 517ms/step - loss: 0.1370 - accuracy: 0.9450 - val_loss: 0.4639 - val_accuracy: 0.8520\n",
      "Epoch 72/100\n",
      "63/63 [==============================] - 33s 516ms/step - loss: 0.1368 - accuracy: 0.9455 - val_loss: 0.4796 - val_accuracy: 0.8450\n",
      "Epoch 73/100\n",
      "63/63 [==============================] - 33s 516ms/step - loss: 0.1584 - accuracy: 0.9350 - val_loss: 0.4497 - val_accuracy: 0.8300\n",
      "Epoch 74/100\n",
      "63/63 [==============================] - 32s 509ms/step - loss: 0.1607 - accuracy: 0.9400 - val_loss: 0.4988 - val_accuracy: 0.8490\n",
      "Epoch 75/100\n",
      "63/63 [==============================] - 32s 508ms/step - loss: 0.1515 - accuracy: 0.9340 - val_loss: 0.4139 - val_accuracy: 0.8610\n",
      "Epoch 76/100\n",
      "63/63 [==============================] - 33s 519ms/step - loss: 0.1350 - accuracy: 0.9470 - val_loss: 0.3878 - val_accuracy: 0.8370\n",
      "Epoch 77/100\n",
      "63/63 [==============================] - 32s 513ms/step - loss: 0.1401 - accuracy: 0.9440 - val_loss: 0.3743 - val_accuracy: 0.8780\n",
      "Epoch 78/100\n",
      "63/63 [==============================] - 34s 540ms/step - loss: 0.1336 - accuracy: 0.9525 - val_loss: 0.3771 - val_accuracy: 0.8770\n",
      "Epoch 79/100\n",
      "63/63 [==============================] - 32s 500ms/step - loss: 0.1383 - accuracy: 0.9500 - val_loss: 0.4525 - val_accuracy: 0.8620\n",
      "Epoch 80/100\n",
      "63/63 [==============================] - 32s 501ms/step - loss: 0.1322 - accuracy: 0.9485 - val_loss: 0.5906 - val_accuracy: 0.7820\n",
      "Epoch 81/100\n",
      "63/63 [==============================] - 32s 505ms/step - loss: 0.1278 - accuracy: 0.9505 - val_loss: 0.6811 - val_accuracy: 0.8300\n",
      "Epoch 82/100\n",
      "63/63 [==============================] - 31s 494ms/step - loss: 0.1281 - accuracy: 0.9505 - val_loss: 0.4436 - val_accuracy: 0.8650\n",
      "Epoch 83/100\n",
      "63/63 [==============================] - 33s 520ms/step - loss: 0.1318 - accuracy: 0.9500 - val_loss: 0.4134 - val_accuracy: 0.8750\n",
      "Epoch 84/100\n",
      "63/63 [==============================] - 32s 511ms/step - loss: 0.1148 - accuracy: 0.9520 - val_loss: 0.3954 - val_accuracy: 0.8800\n",
      "Epoch 85/100\n",
      "63/63 [==============================] - 32s 514ms/step - loss: 0.1405 - accuracy: 0.9420 - val_loss: 0.8298 - val_accuracy: 0.8230\n",
      "Epoch 86/100\n",
      "63/63 [==============================] - 30s 471ms/step - loss: 0.1312 - accuracy: 0.9490 - val_loss: 0.3536 - val_accuracy: 0.8820\n",
      "Epoch 87/100\n",
      "63/63 [==============================] - 31s 492ms/step - loss: 0.1372 - accuracy: 0.9465 - val_loss: 0.3339 - val_accuracy: 0.8830\n",
      "Epoch 88/100\n",
      "63/63 [==============================] - 33s 520ms/step - loss: 0.1157 - accuracy: 0.9535 - val_loss: 0.3872 - val_accuracy: 0.8680\n",
      "Epoch 89/100\n",
      "63/63 [==============================] - 34s 537ms/step - loss: 0.1233 - accuracy: 0.9515 - val_loss: 0.4416 - val_accuracy: 0.8780\n",
      "Epoch 90/100\n",
      "63/63 [==============================] - 32s 510ms/step - loss: 0.1163 - accuracy: 0.9515 - val_loss: 0.4515 - val_accuracy: 0.8730\n",
      "Epoch 91/100\n",
      "63/63 [==============================] - 31s 490ms/step - loss: 0.1281 - accuracy: 0.9500 - val_loss: 0.9718 - val_accuracy: 0.7670\n",
      "Epoch 92/100\n",
      "63/63 [==============================] - 33s 517ms/step - loss: 0.1120 - accuracy: 0.9605 - val_loss: 0.5011 - val_accuracy: 0.8460\n",
      "Epoch 93/100\n",
      "63/63 [==============================] - 33s 521ms/step - loss: 0.1338 - accuracy: 0.9465 - val_loss: 0.4105 - val_accuracy: 0.8760\n",
      "Epoch 94/100\n",
      "63/63 [==============================] - 32s 506ms/step - loss: 0.1290 - accuracy: 0.9445 - val_loss: 0.5118 - val_accuracy: 0.8490\n",
      "Epoch 95/100\n",
      "63/63 [==============================] - 26s 418ms/step - loss: 0.0927 - accuracy: 0.9620 - val_loss: 0.4702 - val_accuracy: 0.8660\n",
      "Epoch 96/100\n",
      "63/63 [==============================] - 32s 504ms/step - loss: 0.1117 - accuracy: 0.9610 - val_loss: 0.5311 - val_accuracy: 0.8690\n",
      "Epoch 97/100\n",
      "63/63 [==============================] - 31s 498ms/step - loss: 0.0922 - accuracy: 0.9640 - val_loss: 0.3964 - val_accuracy: 0.8670\n",
      "Epoch 98/100\n",
      "63/63 [==============================] - 31s 497ms/step - loss: 0.1088 - accuracy: 0.9580 - val_loss: 0.5409 - val_accuracy: 0.8420\n",
      "Epoch 99/100\n",
      "63/63 [==============================] - 33s 518ms/step - loss: 0.1074 - accuracy: 0.9605 - val_loss: 1.3448 - val_accuracy: 0.7500\n",
      "Epoch 100/100\n",
      "63/63 [==============================] - 33s 523ms/step - loss: 0.1021 - accuracy: 0.9600 - val_loss: 0.3840 - val_accuracy: 0.8810\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss=\"binary_crossentropy\",\n",
    "              optimizer=\"rmsprop\",\n",
    "              metrics=[\"accuracy\"])\n",
    "history = model.fit(\n",
    "    train_dataset,\n",
    "    epochs=100,\n",
    "    validation_data=validation_dataset)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "chapter09_part02_modern-convnet-architecture-patterns.i",
   "private_outputs": false,
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('finbert')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "dc2d75d2bbb1ab8d2c49183bedcbafe25b599ed2fa73b8834cc66076892a6e29"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
